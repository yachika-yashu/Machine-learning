{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIFtQxSws6MDbOWSl0y7uE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yachika-yashu/Machine-learning/blob/main/Batch_gradient_descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_7rb6L-iSzC"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = load_diabetes(return_X_y=True) #dataset\n"
      ],
      "metadata": {
        "id": "gfPRsUE9ihpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normal linear regression **"
      ],
      "metadata": {
        "id": "-6_Ywis_uWXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train,y_train)\n",
        "print(reg.coef_)\n",
        "print(reg.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE0Er9lfiyLR",
        "outputId": "890b0744-79c4-48c4-b7ed-0937021010bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10)\n",
            "(442,)\n",
            "[  -9.15865318 -205.45432163  516.69374454  340.61999905 -895.5520019\n",
            "  561.22067904  153.89310954  126.73139688  861.12700152   52.42112238]\n",
            "151.88331005254167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 columns so we got 10 coeff"
      ],
      "metadata": {
        "id": "g9LDHY78jKz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uftFRdbbjKQg",
        "outputId": "6b026cf1-f00a-4b9e-a218-3a3f212a6835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(353, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = reg.predict(X_test)\n",
        "r2_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad6CSyXNjBlM",
        "outputId": "3e4a8d8f-6aae-4d1f-ffea-d6fc27b3556e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4399338661568968"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch Gradient descent**"
      ],
      "metadata": {
        "id": "B6vw8qJtudsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin by allowing the user to set the number of epochs and the learning rate (lr). To train the linear regression model, we first initialize the parameters: the intercept (b0) is set to 0, and all the feature coefficients (b1, b2, ..., bn) are initialized to 1. The goal during training is to adjust these parameters so they minimize the loss function (typically Mean Squared Error).\n",
        "\n",
        "In each epoch, we calculate the predicted values (y_hat) using the current parameters. The prediction formula is:\n",
        "\n",
        "y_hat = b0 + b1*x1 + b2*x2 + ... + bn*xn\n",
        "Once we have the predictions, we compute the gradients (slopes) of the loss function with respect to each parameter. These gradients tell us how much to adjust each parameter to reduce the error.\n",
        "\n",
        "For the intercept (b0), the gradient is:\n",
        "\n",
        "∂L/∂b0 = -2 * mean(y_train - y_hat)\n",
        "For each coefficient (bi), the gradient is:\n",
        "\n",
        "∂L/∂bi = -2 * mean((y_train - y_hat) * x_train_i)\n",
        "where x_train_i is the column of the training data corresponding to feature i.\n",
        "\n",
        "We then update each parameter using gradient descent:\n",
        "\n",
        "b0 = b0 - lr * ∂L/∂b0\n",
        "bi = bi - lr * ∂L/∂bi\n",
        "This process is repeated for the specified number of epochs. With each iteration, the model parameters (b0, b1, ..., bn) are gradually adjusted in the direction that reduces the prediction error. Over time, the model learns the optimal values of the coefficients that best fit the training data."
      ],
      "metadata": {
        "id": "Jgxo_TTJjnL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GDRegressor:\n",
        "  def __init__(self,learning_rate=0.01,epochs=100):\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "    self.intercept_=0 #b0=0\n",
        "    self.coef_=np.ones(X_train.shape[1]) # we will have b1----bn we will set them ones,\n",
        "    # but how many columns we have that many b we will define because y=b0=+b1x1+b2*x2----\n",
        "\n",
        "    for i in range(self.epochs):\n",
        "      y_hat = self.intercept_+np.dot(X_train,self.coef_) #yhat=b0+b1*x+b2*x2+.....\n",
        "      intercept_der = -2*np.mean(y_train-y_hat) #  ∂l/∂b0=−2/n( i=1 to n ∑  (yi-yihat)\n",
        "      #y1 hai output column of training data and yhat predections on ytrain\n",
        "\n",
        "\n",
        "      coef_der=-2*np.dot((y_train-y_hat),X_train)/X_train.shape[0] #∂l/∂b1=−2( i=1 to n ∑  ((yi-yihat)*xtrain)/x_train_n_rows)\n",
        "      #y1 hai output column of training data and yhat predections on ytrain\n",
        "\n",
        "\n",
        "      self.intercept_=self.intercept_-(self.lr*intercept_der)\n",
        "      self.coef_=self.coef_-(self.lr*coef_der)\n",
        "\n",
        "    print(self.intercept_,self.coef_)  #1 baar update hoga pura data pr slope aur directions change krk finally ek value aayegi\n",
        "\n",
        "\n",
        "  def predict(self,X_test):\n",
        "    return np.dot(X_test,self.coef_) + self.intercept_"
      ],
      "metadata": {
        "id": "RciMoSQTjl7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdr = GDRegressor(epochs=1000,learning_rate=0.5)\n",
        "gdr.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "ZCmHFqGIp-Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = gdr.predict(X_test)"
      ],
      "metadata": {
        "id": "VaA8OdotsWkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7UOIZLVsZPD",
        "outputId": "73e9cadb-20cc-49a1-c635-fb490dec2a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4534503034722803"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1p2PRFXFjlhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "gdr.fit(X_train,y_train)\n",
        "print(\"The time taken is\",time.time() - start)"
      ],
      "metadata": {
        "id": "VeNU9dlUEZVG",
        "outputId": "ebfaadeb-9ef3-4338-a53a-2c82d78e5814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152.01351687661833 [  14.38990585 -173.7235727   491.54898524  323.91524824  -39.32648042\n",
            " -116.01061213 -194.04077415  103.38135565  451.63448787   97.57218278]\n",
            "The time taken is 0.14699125289916992\n"
          ]
        }
      ]
    }
  ]
}